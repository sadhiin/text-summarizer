2025-02-10 14:44:55,685 - __main__ - INFO - main.py - 10 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Ingestion Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 14:44:55,687 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 18 - Creating the directory artifacts/data_ingestion/summarizer-data.zip
2025-02-10 14:44:55,688 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 25 - Downloading data from https://github.com/krishnaik06/datasets/raw/refs/heads/main/summarizer-data.zip
2025-02-10 14:44:56,285 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 48 - Extracting zip file to artifacts/data_ingestion
2025-02-10 14:44:56,286 - __main__ - INFO - main.py - 13 - âœ…âœ…âœ… Completed Data Ingestion Stage âœ…âœ…âœ…
2025-02-10 14:44:56,286 - __main__ - INFO - main.py - 17 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Trasnformation Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 14:45:06,123 - __main__ - INFO - main.py - 20 - âœ…âœ…âœ… Completed Data Trasnformation Stage âœ…âœ…âœ…
2025-02-10 16:28:45,899 - __main__ - INFO - main.py - 11 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Ingestion Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:28:45,903 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 18 - Creating the directory artifacts/data_ingestion/summarizer-data.zip
2025-02-10 16:28:45,903 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 25 - Downloading data from https://github.com/krishnaik06/datasets/raw/refs/heads/main/summarizer-data.zip
2025-02-10 16:28:46,517 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 48 - Extracting zip file to artifacts/data_ingestion
2025-02-10 16:28:46,517 - __main__ - INFO - main.py - 14 - âœ…âœ…âœ… Completed Data Ingestion Stage âœ…âœ…âœ…
2025-02-10 16:28:46,517 - __main__ - INFO - main.py - 18 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Trasnformation Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:28:56,500 - __main__ - INFO - main.py - 21 - âœ…âœ…âœ… Completed Data Trasnformation Stage âœ…âœ…âœ…
2025-02-10 16:28:56,501 - __main__ - INFO - main.py - 24 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Model Training Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:29:07,269 - __main__ - ERROR - main.py - 31 - Error in Model Training Stage: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 3.06 MiB is free. Process 333324 has 13.87 GiB memory in use. Process 386602 has 898.00 MiB memory in use. Of the allocated memory 796.45 MiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-10 16:29:56,758 - __main__ - INFO - main.py - 11 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Ingestion Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:29:56,762 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 30 - File artifacts/data_ingestion/summarizer-data.zip/summarizer-data.zip already exists
2025-02-10 16:29:56,941 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 48 - Extracting zip file to artifacts/data_ingestion
2025-02-10 16:29:56,942 - __main__ - INFO - main.py - 14 - âœ…âœ…âœ… Completed Data Ingestion Stage âœ…âœ…âœ…
2025-02-10 16:29:56,942 - __main__ - INFO - main.py - 18 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Trasnformation Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:29:59,387 - __main__ - INFO - main.py - 21 - âœ…âœ…âœ… Completed Data Trasnformation Stage âœ…âœ…âœ…
2025-02-10 16:29:59,388 - __main__ - INFO - main.py - 24 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Model Training Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:30:06,470 - __main__ - ERROR - main.py - 31 - Error in Model Training Stage: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 3.06 MiB is free. Process 333324 has 13.87 GiB memory in use. Process 390913 has 898.00 MiB memory in use. Of the allocated memory 796.45 MiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-10 16:32:32,128 - __main__ - INFO - main.py - 12 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Ingestion Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:32:32,132 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 30 - File artifacts/data_ingestion/summarizer-data.zip/summarizer-data.zip already exists
2025-02-10 16:32:32,327 - src.textSummarizer.components.data_ingestion - INFO - data_ingestion.py - 48 - Extracting zip file to artifacts/data_ingestion
2025-02-10 16:32:32,327 - __main__ - INFO - main.py - 15 - âœ…âœ…âœ… Completed Data Ingestion Stage âœ…âœ…âœ…
2025-02-10 16:32:32,498 - __main__ - INFO - main.py - 20 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Data Trasnformation Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:32:34,575 - __main__ - INFO - main.py - 23 - âœ…âœ…âœ… Completed Data Trasnformation Stage âœ…âœ…âœ…
2025-02-10 16:32:34,732 - __main__ - INFO - main.py - 29 - ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ Starting Model Training Stage ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸ğŸƒğŸ¼â€â¡ï¸
2025-02-10 16:32:41,837 - __main__ - ERROR - main.py - 38 - Error in Model Training Stage: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 3.06 MiB is free. Process 333324 has 13.87 GiB memory in use. Process 400231 has 898.00 MiB memory in use. Of the allocated memory 796.45 MiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
